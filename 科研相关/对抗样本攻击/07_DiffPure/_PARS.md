## PARS

---

### 一句话概括

最基础的diffpure，通过控制加噪程度t来洗去对抗扰动，有净化力度和语义的trade off，速度慢

---

### Problem

即为最开始的对抗样本，如何防住对抗样本，提高模型鲁棒性

---

### Approach

使用diffusion的数学模型和unet的网络架构，通过加噪再去噪，洗去对抗扰动。其中控制超参数 $t^*$ 尤为关键，一般在 $0.1$ 左右

---

### Result

理论上，证明了随着超参数t的增大，干净样本和对抗样本的KL散度在下降，也就是加噪越多，对抗样本会逐渐贴近干净样本；净化后图和原图差距不仅取决于对抗扰动，还取决于t

实验上，在cifar10，imagenet，celeba-hq三个数据集上，对于各种攻击（linf，l2，stadv），对于各种目标分类器，基本都达到了sota水平

然后净化的时间长

---

### Summary

是基于diffusion净化的鼻祖，为后续研究打下了扎实的基础。

不足：
- 对随机性的防御效果没有深入研究（sde ode）
- 净化时间太慢
- 净化和语义需要trade-off

个人认为大方向是正确的，通过将样本拉回流形来防御对抗扰动，所以是对不同分类器泛用的；但是未深入研究随机性的作用
