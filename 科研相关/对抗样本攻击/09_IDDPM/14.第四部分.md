**Section 4 (Experiments)** 是这篇论文的“秀肌肉”环节。

不同于 Section 3 的机理分析和消融实验，Section 4 的重点是**“刷榜”**。作者在标准的图像数据集上，拿 IDDPM 和当时所有的顶尖选手（Base DDPM, GANs, VAEs, Flows）进行打擂台。

对你的 DiffPure 研究来说，这一章主要看点在于：**明确 IDDPM 在不同维度上的上限在哪里**，从而预估它作为 DiffPure 基座时的性能天花板。

这一章分为三个主要战场：

---

### 1. 战场一：对数似然 (NLL) 的比拼 (4.1 Log-likelihood Comparison)
**—— 证明 IDDPM 是一个严谨的概率模型**

*   **数据集：** CIFAR-10, ImageNet 64x64, LSUN。
*   **对手：** 各种 VAE（Very Deep VAE）、Flow 模型（Glow）、自回归模型（PixelCNN）。这些模型以前在 NLL 指标上是碾压 DDPM 的。
*   **结果 (Table 1 & 2)：**
    *   **ImageNet 64x64：** IDDPM 达到了 **3.52 bits/dim**，甚至超过了某些自回归模型。这是个巨大的突破，因为扩散模型以前被认为只能画图，不能做密度估计。
    *   **CIFAR-10：** 提升极其显著，从 DDPM 的 3.75 降到了 2.94（越低越好）。
*   **对 DiffPure 的启示：**
    *   高 NLL 意味着模型对图像流形的建模非常精确。
    *   这意味着当攻击者把图像推离流形（Adversarial Example）时，IDDPM 能非常敏锐地感知到“这个分布不对劲”，并有更大的概率把它拉回来。**这是 IDDPM 适合做防御的数学基石。**

---

### 2. 战场二：生成质量 (Sample Quality) 的比拼 (4.2 Sample Quality)
**—— 证明 IDDPM 画图依然是最牛的**

*   **指标：** FID (Fréchet Inception Distance) —— 衡量生成的图够不够“真”。
*   **结果：**
    *   **CIFAR-10：** FID 达到了 **2.90**。这在当时是非常顶级的成绩，和顶级 GAN 处于同一梯队。
    *   **LSUN：** 在教堂（Church）、卧室（Bedroom）等类别上，生成的细节极其逼真。
    *   **更重要的发现：**
        作者展示了 **Sample speed vs. Quality** 的曲线（Figure 2）。
        *   DDPM 的线是平的，但起点很远（必须 1000 步）。
        *   IDDPM 的线是陡峭上升的。**仅需 50 步**，FID 就已经能看了；**100 步**时几乎达到最优。
*   **对 DiffPure 的启示：**
    *   DiffPure 的防御过程需要在线进行（推理时防御），速度至关重要。
    *   这里的实验告诉你：**设置 `timesteps = 100` 是一个性价比极高的选择。** 既能保证清洗干净（画质好），又不会让防御过程太慢。

---

### 3. 战场三：分布覆盖率 (Distribution Coverage) (4.3 Distribution Coverage)
**—— 致命一击：GAN 的死穴**

这是本章**最有价值**的一个实验，特别是对于安全领域。

*   **痛点：** GAN 虽然 FID 好，但它有 Mode Collapse 问题。它经常只记住数据集里的一小部分样本，而忽略其他的。
*   **指标：** Recall (召回率)。
    *   **Precision：** 生成的图有多少是像真的。
    *   **Recall：** 真实的图有多少能被生成出来。
*   **结果 (Table 3)：**
    *   **StyleGAN2 (当时的 GAN 霸主)：** Recall 只有 **0.49** 左右。意味着它丢掉了一半的数据分布！
    *   **IDDPM：** Recall 高达 **0.57 - 0.63**。
*   **结论：** 扩散模型的覆盖率**碾压** GAN。
*   **对 DiffPure 的启示（重中之重）：**
    *   防御对抗样本本质上是一个“去噪+重构”的过程。
    *   如果攻击者针对的是一个非常罕见的图像特征（Long-tail features），GAN 可能根本重构不出来（因为它之前 Mode Collapse 丢掉了这部分分布），导致防御失败。
    *   IDDPM 的高 Recall 保证了：**无论攻击者怎么畸变图像，只要它还在自然图像的范畴内，IDDPM 都有能力把它找回来。**

---

### 4. 总结：Section 4 给你的“定心丸”

读完 Section 4，你应该对选择 IDDPM 做基座充满信心：

1.  **数学上站得住脚：** NLL 很高，概率建模准确。
2.  **速度上能打：** 50-100 步就能用，不像老 DDPM 那样慢如蜗牛。
3.  **安全性更强：** 高 Recall 意味着没有盲区，是做鲁棒性防御的最佳人选。

到这里，整篇论文的核心内容就结束了。读完这四章，再加上消融实验，你对 DiffPure 为什么要选这个模型、为什么要用那套 Loss 应该已经了然于胸了。