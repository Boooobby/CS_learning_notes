好的，我们进入 **Section 4: DENSEPURE**。

如果说 **Section 3** 是给审稿人看的“理论物理书”（证明我是对的），那么 **Section 4** 就是给你我这样的工程师看的 **“施工手册”**（教你怎么把代码跑起来）。

这一节虽然短，但是**全是干货**。你后面复现代码时，所有的核心逻辑和超参数都在这里。

作者把 DensePure 的实现拆解成了三个关键步骤：

---

### 第一步：对齐噪声（Step 1: Estimating $n$） —— 最容易忽视的一步！

这是将 **随机平滑（Randomized Smoothing）** 和 **扩散模型（Diffusion）** 结合的接口。

*   **问题**：
    *   **随机平滑**说：“我要给图片加高斯噪声，噪声强度是标准差 $\sigma$。”
    *   **扩散模型**说：“我不懂什么 $\sigma$，我只认识时间步 $t$（或者离散步数 $n$）。”
    *   我们需要把 $\sigma$ 翻译成扩散模型能听懂的 $n$。

*   **计算公式**：
    $$ \alpha_n = \frac{1}{1+\sigma^2} $$
    *   这是怎么来的？这是信噪比（Signal-to-Noise Ratio）的匹配。
    *   **操作**：你在代码里会看到一个循环，遍历扩散模型所有的步数（比如 0 到 1000），找到那个 $\bar{\alpha}_t$ 最接近 $\frac{1}{1+\sigma^2}$ 的时刻 $n$。
    *   **意义**：这一步确立了我们的**起点**。当攻击者给图片加了 $\sigma$ 的噪声后，在扩散模型眼里，这张图就等同于处于时刻 $n$ 的半噪声图 $x_n$。

---

### 第二步：多轮净化（Step 2: Multiple Runs of Reverse Process） —— 核心算法

这是 DensePure 的灵魂，对应了理论部分的“寻找最大概率点”。

*   **输入**：
    *   这就是那个加了随机平滑噪声的图 $x_{rs} = x + \epsilon$。
    *   注意：要先缩放！输入给扩散模型的不是 $x_{rs}$，而是 $\sqrt{\alpha_n} x_{rs}$（因为扩散模型假设数据方差是被 normalize 过的）。

*   **循环 $K$ 次（关键参数 $K$）**：
    *   对于**同一个**输入噪声图，用**不同的随机种子**运行扩散模型的去噪过程 $K$ 次。
    *   **结果**：你得到了 $K$ 张不一样的“复原图” $\{\hat{x}_0^1, \hat{x}_0^2, ..., \hat{x}_0^K\}$。
    *   *注：这就是理论中为了逼近 $P(x|x_t)$ 这个分布，通过多次采样来覆盖它。*

---

### 第三步：多数投票（Step 3: Majority Vote） —— 决策层

这就很简单了，把那 $K$ 张图扔给分类器。

*   **投票**：
    $$ \hat{y} = \text{arg}\max_c \sum_{i=1}^K \mathbb{1}\{f(\hat{x}_0^i) = c\} $$
*   **翻译**：统计 $K$ 张图里，哪个类别出现的次数最多，那个类别就是最终判定。

---

### 第四步：快速采样（Fast Sampling / Parameter $b$） —— 救命稻草

这一段是为了解决**速度**问题。这也是你复现时必须注意的。

*   **背景**：标准的 DDPM 去噪需要一步一步走（$n, n-1, ..., 1$）。如果 $n=100$，你就得进出神经网络100次。如果你还要跑 $K=40$ 轮投票，那一张图就要跑 $100 \times 40 = 4000$ 次网络，简直慢到不可接受。

*   **解决方案**：**跳步采样（Strided Sampling）**。
    *   我们不一步步走，而是“大跨步”走。
    *   **参数 $b$ (Subsequence size)**：比如原来要走100步，我现在只走 $b=10$ 步。也就是取一个子序列 $S_b = \{n, \dots, 1\}$。
    *   作者引用了 Nichol & Dhariwal (2021) 的方法来调整噪声系数 $\beta$，保证跳步走的时候数学上依然大致成立。

*   **DensePure vs Carlini 的区别**：
    *   **Carlini (DiffPure)** 通常使用“一步到位”或极少的步数（One-shot），这导致生成质量单一且确定性强。
    *   **DensePure** 强调 $b > 1$。必须多走几步，才能引入足够的随机性，才能体现出“后验分布”的多样性，投票才有意义。

---

### Section 4 给复现者的 **Checklist**

在你看代码时，请重点通过 Section 4 确认以下三个超参数：

1.  **$\sigma$ (Noise Level)**：
    *   通常取 0.25, 0.50, 1.00。
    *   这决定了你要防多大的攻击，也决定了你在 Step 1 中计算出的起始步数 $n$ 是多少。

2.  **$K$ (Voting Number)**：
    *   文中提到 $K$ 是投票次数。
    *   实验部分你会看到通常设为 **40** 左右。这是精度和速度的 Trade-off。

3.  **$b$ (Sampling Steps)**：
    *   文中提到这是 Fast Sampling 的步数。
    *   实验部分你会看到通常设为 **10** 左右（不是由扩散模型原本的1000步全跑完，而是只采10个关键点）。

**总结 Section 4：**
这就是在这个“并集凸集”理论指导下的具体行动指南：
**先算出起点 $n$，然后大跨步 $b$ 往回走，走 $K$ 次，最后投票定输赢。**