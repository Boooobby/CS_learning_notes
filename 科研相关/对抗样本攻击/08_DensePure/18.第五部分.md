**Section 5 (EXPERIMENTS)** 是其实验验证部分。

如果说 **Section 3** 画了一张大饼（理论很完美），**Section 4** 给了做饼的菜谱（算法步骤），那么 **Section 5** 就是把饼做出来，喂给评委吃，证明它确实比别人的好吃（SOTA 性能）。

这一节对于你的科研来说，**不仅仅是看那个“胜出”的数字**，更重要的是看作者是如何设计实验来**填补理论与现实的鸿沟**，以及如何通过**消融实验 (Ablation Study)** 来证明他的每一个设计选择都是有道理的。

我们将 Section 5 拆解为三个关键维度：

---

### 第一维度：实验设置 (The Setup) —— 这里的“潜规则”

在看结果之前，必须先看懂他是怎么“摆擂台”的。这里有几个关键点决定了他的实验可信度：

1.  **Off-the-shelf (现成即用)**：
    *   作者反复强调他们用的是 **Pre-trained Diffusion Model** 和 **Pre-trained Classifier**。
    *   **意义**：这说明 DensePure 不需要像对抗训练（Adversarial Training）那样，针对每一种攻击去重新烧钱训练模型。这是一种 **“即插即用”** 的防御。你的复现工作也会轻松很多，不用自己从头训大模型。

2.  **基准线 (The Rival)**：
    *   **Carlini et al. (2022)**：这是 DensePure 最主要的假想敌。
    *   为什么？还记得上一节说的吗？Carlini 用的是 One-shot（一次采样）。DensePure 用的是 Multi-shot Voting（多次采样投票）。
    *   **逻辑**：只要我赢了 Carlini，就证明了我的 **“投票 + 凸集并集理论”** 是对的。

3.  **评估标准**：
    *   **Certified Robustness (Randomized Smoothing)**：这里比的不是“谁能防住 PGD 攻击”，而是“谁算出来的**认证半径 $R$ 大**”。
    *   这是一个**硬指标**。在半径 $R$ 内，上帝来了也攻不破。这比 empirical robustness（经验鲁棒性）要高级。

---

### 第二维度：主要结果 (Main Results) —— 碾压局

作者在这个环节展示了 DensePure 是当之无愧的 SOTA（State of the Art）：

1.  **ImageNet 上的完胜 (+7%)**：
    *   在 CIFAR-10 上，大家分差还没那么大。但在 ImageNet 这种高清、复杂的图像上，DensePure 展现了统治力。
    *   **原因分析**：如果你还记得 Section 3 的理论，高维空间里，“凸集并集”带来的体积红利比低维空间大得多。ImageNet 维度高，所以 DensePure 相比传统方法的优势被放大了。

2.  **曲线分离 (Figure 3)**：
    *   看论文里的 **Figure 3**。横轴是攻击半径（扰动大小），纵轴是准确率。
    *   随着攻击越来越狠（半径变大），DensePure 的线掉得比 Carlini 慢。
    *   **硬逻辑**：这证明了那个 **“并集”** 真的很大。当扰动大到跳出了单一的“凸集房间”时，One-shot 方法（Carlini）可能就挂了，但 Voting 方法（DensePure）可能跳进了隔壁的“凸集房间”（属于同一个 Union），所以还能救回来。

---

### 第三维度：消融实验 (Ablation Study) —— 这里的“反直觉”是精华！

这是 Section 5 对你**启发最大**的部分。作者通过控制变量，回答了两个核心问题。

#### 1. 为什么要投票？($K$ 的影响)
*   **实验**：测试不同的投票次数 $K \in \{1, 10, 20, 40...\}$。
*   **结果**：$K$ 越大，鲁棒性越高，大约在 $K=40$ 时饱和。
*   **启示**：这直接验证了 Section 3 的理论 —— **后验分布 $P$ 是存在的，采样的点越多，越能通过大数定律逼近这个分布的真实意图（Mode）**。

#### 2. 为什么要多步采样？($b$ 的影响) —— **高能反转！**
作者对比了 $b$（Fast Sampling 的步数，比如走 2 步还是走 10 步）。这里出现了一个极具反直觉的现象，请务必注意：

*   **情况 A：如果不投票（No Majority Vote）**
    *   **结果**：$b$ 越大（走的步数越多），鲁棒性反而**越差**！
    *   **为什么？**
        *   走的步数越多，引入的随机噪声累积就越多。
        *   对于单次采样，过多的随机性会导致结果“飘”到错误的区域去。这就像你只有一次机会射击，枪的后坐力（随机性）越大，你越容易脱靶。

*   **情况 B：如果投票（With Majority Vote）**
    *   **结果**：$b$ 越大（走的步数越多），鲁棒性**越好**！
    *   **为什么？**
        *   步数多 $\rightarrow$ 图像质量高（画得像真图） $\rightarrow$ 分类更容易对。
        *   步数多 $\rightarrow$ 随机性大 $\rightarrow$ 探索的“凸集房间”更多。
        *   **投票机制（Voting）**把“随机性”从**毒药**变成了**解药**。虽然单次容易脱靶，但我开了40枪，散布在大靶心周围，统计一下重心，反而比打一枪要准得多。

**这个对比实验是 DensePure 的点睛之笔。** 它完美解释了为什么之前的 Carlini 方法（One-shot）不敢多走几步，而 DensePure 敢。

---

### 对你的科研启发

你在复现和找 Idea 时，Section 5 告诉你：

1.  **Idea 来源**：看消融实验里那些 **“反直觉”** 或者是 **“Trade-off”** 的地方。
    *   比如：$K$ 越大越好，但计算量大了 40 倍，很慢。你有没有办法做到 $K=5$ 就能达到 $K=40$ 的效果？（比如蒸馏？比如更聪明的采样？）
    *   比如：$b$ 越大质量越好但随机性不可控。你有没有办法控制这个随机性，让它只再“好”的方向上随机？（比如加 Guide？）

2.  **实验设计**：等到你自己写论文时，一定要学它的 **5.2 Ablation Study**。
    *   不要只放一个 SOTA 的结果。
    *   要通过控制变量法，把你的每一个改进点（Step 1, Step 2...）的贡献拆出来给审稿人看。告诉他们：“这几个点的提升不是运⽓，是我的设计生效了。”

**总结 Section 5：**
验证了扩散模型在 ImageNet 这种很难的数据集上极强，并且通过 $b$ 的反直觉实验，实锤了 **“高质量生成 + 强随机性 + 多数投票”** 这个组合拳是成功的关键。