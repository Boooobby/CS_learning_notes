
**姓名：** 鲍至雍  
**年级：** 信安大二  
**研究方向：** 基于扩散/流模型的对抗样本净化防御

---

## 一、研究背景与目标

**总体研究方向：** 针对深度学习模型面临的对抗样本攻击问题，研究基于生成模型（Diffusion / Flow Model）的净化防御方法，重点关注对白盒攻击的鲁棒防御。

**本阶段完成的任务：**
- 大量阅读相关论文，构建了较完整的知识体系
- 复现重要代码，包括diffpure（开山作）和adbm（优化版本）
- 尝试提出了自己的idea，但是被证明无用

---

## 二、文献阅读总结

### 2.1 对抗攻击方法（基础）

| 论文 | 核心思想 | 个人评价 |
|------|---------|---------|
| FGSM (Goodfellow et al., 2015) | 神经网络高维过于线性导致不鲁棒 | 对抗样本攻击的开端 |
| PGD (Madry et al., 2018) | 把对抗攻击形式化成一个min-max博弈，像训练网络一样通过梯度下降，找到局部最优的攻击样本 | 古老但是沿用至今的白盒攻击手段 |
| C&W (Carlini & Wagner, 2017) | 把攻击变成一个优化问题 | 和PGD一样是经典benchmark |

- **小结：** PGD是最通用的白盒攻击，在各个范数下都具有威胁性（L2，Linf）

### 2.2 生成模型基础

| 论文 | 核心思想 | 个人评价 |
|------|---------|---------|
| DDPM (Ho et al., 2020) | 通过学习如何去噪，来学习真实数据流形 | 定义了一种新的生成模型范式，并提出了DDPM这个离散化采样方式 |
| DDIM (Song et al., 2021a) | DDPM是带有随机性的，而DDIM去掉了随机性，并支持跳步采样 | diffusion的另一种离散化采样方式 |
| IDDPM (Nichol & Dhariwal, 2021) | 优化了diffusion底层 | 未深入了解 |
| Score-based SDE (Yang Song et al., 2021) | 以微分方程统一了diffusion各个流派的数学过程，去噪其实可以看作是在求解微分方程 | 神作，统一了数学，并提出了ODE和SDE这两种连续采样方式（DDPM和DDIM是离散化的） |
| Flow Matching | 流模型包含了diffusion，不像diffusion必须通过加噪去噪来生成，而是可以在任意两个分布间，定义任意形状的路径 | 灵活性高，并且在flow-based的净化中胜过diffusion-based |

- **小结：** 以底层数学原理为主

### 2.3 ==基于扩散模型的净化防御==（核心方向）

| 论文 | 会议/期刊 | 核心方法 |
|------|----------|---------|
| **DiffPure** | ICML 2022 | 通过讲对抗样本加噪到一定程度来尝试淹没对抗扰动，再依靠diffusion的生成能力恢复图像 |
| **DensePure** | ICLR 2023 | 在diffpure的基础上进行多数投票 |
| **GuidedPure** | arxiv 2022 | 恢复图像时加入引导机制 |
| **OSCP** | CVPR 2025 | 用LCM在隐空间做净化，通过数学推导优化训练过程，并引入了图像重建时的引导过程 |
| **ADBM** | ICLR 2025 | 引入桥模型，直接连接对抗样本和干净样本两个分布 |
| **==FlowPure==** | arxiv 2025 | 利用flow的强大生成能力来做净化 |
| **==DiffBreak==** | NIPS 2025 | 这是攻击方法，修复了之前攻击算不准梯度的缺点，并新提出了一个LF（低频）攻击，对目前净化方法有毁灭性打击 |
| **FreqPure** | ICML 2025 | 分析对抗扰动的频域特征，发现破坏集中在高频部分 |

**==补充和评价==：** 
- 自从diffpure，净化就一直有一个**trade off**——加噪少了洗不掉噪声，多了图像原本语义也没了。diffpure的一个最重要的理论就是：加噪越多，干净样本和对抗样本这两个分布越接近。
- 但是OSCP和ADBM证明了在噪声少的情况下，分布离得还是很远，所以这两个方法都修改了**Loss**，修改成同时去高斯噪声和对抗噪声。
- DensePure走的是可认证鲁棒性的路，通过数学计算算出鲁棒性下界。缺点极为明显：多次采样极慢，并且可认证鲁棒性只在L2范数下生效
- 但是最近这两篇FlowPure和DiffBreak里面用到了**目前最强的攻击**（其实就是修复了之前攻击的不足），导致目前所有模型的白盒鲁棒性跳水（如原本在cifar10上adbm可以达到70的rob acc，但是在这个精确攻击下只有32，并且在DiffBreak提出的LF攻击下，只有7）。
- 在这种情况下，flowpure是提倡**不要再以白盒鲁棒性为唯一标准**，而diffbreak呼吁去寻找一个**推理时有强随机性的净化过程**。

### 2.4 相关技术储备

| 论文/技术 | 与研究方向的关联 |
|-----------|----------------|
| ControlNet | 可以用来引入引导条件 |
| Consistency Model (CM) | 加速用，一步净化 |
| Latent Consistency Model (LCM) | 加速用，但是还要过一层VAE |
| DFT | 打开图像的频域视角 |

---

## 三、代码复现

### 3.1 DiffPure 复现

- **代码来源：** 官方仓库，稍微修改
- **github：** https://github.com/Boooobby/new-dp
- **实验环境：** py3.10 cuda11.8 1*4090D
- **复现结果：**
  - 成功跑通
  - 对于原版diffpure，攻击者使用PGD100步 EOT10步，裸分类器准确率为0，加上净化器后，良性准确率在90左右，鲁棒性在40左右
  - 对于adbm微调版本，攻击者使用PGD100步 EOT20步，裸分类器准确率为0，加上净化器后，良性准确率在89左右，鲁棒性在54左右

### 3.2 ADBM 复现

- **代码来源：** 自己重构
- **github：** https://github.com/Boooobby/new-adbm
- **实验环境：** py3.10 cuda11.8 1*4090D
- **复现结果：** 成功修改了loss，并且得到了微调后的模型权重

---

## 四、Idea 探索

### 4.1 已探索但未成立的 Idea（AI概括）

**Idea 描述：**
在预训练 Flow 模型的推理时 ODE 求解过程中，引入分段的 Patch-wise 随机正交变换（Randomized Orthogonal Path Folding, ROPF）。具体做法是：将图像按 patch 展平后乘以随机正交矩阵 $R_k$，在变换后的坐标系中求解 ODE（向量场复用公式为 $\tilde{v} = R_k \cdot v_\theta(R_k^T y_t, t)$），并在若干时间断点处切换到新的正交矩阵（坐标系跳跃）。整个过程无需修改预训练模型的任何参数，最终通过 $x_0 = R^T y_0$ 解密回图像空间。

核心论点是：由于攻击者不知道随机种子，无法获知具体的 $R_k$，白盒攻击的梯度反向传播路径被随机正交变换打乱，EOT 因正交群的高维自由度（$10^6$+ 量级）而收敛极慢，从而在计算上使白盒攻击不可行。

**不成立的原因：**
该方案存在一个根本性的数学缺陷：**正交变换是完美可逆的保距变换，在最终输出时被完全抵消，整个方案在数据空间中等价于标准 Flow purification，没有任何区别。**

可以严格证明：将 ROPF 的每一步展开化简后，所有的 $R_k$ 因为 $R^T R = I$ 而逐步消去，最终：

$$x_0^{ROPF} \equiv x_0^{\text{标准 Flow}}$$

逐比特完全相同。正交变换只是改变了计算图的形式（在变换空间 $Y$ 中看到的是折线轨迹），但数据空间 $X$ 中的物理 ODE 轨迹从未发生任何改变。

因此，白盒攻击者完全可以无视正交变换的存在，直接对等价的标准 Flow purification 求梯度，BPDA 和 EOT 均可直接穿透，防御形同虚设。正交变换的"高维自由度"从未真正参与到安全性中。

**从中学到的：**

1. **可逆变换不能提供安全性**：任何在推理链路中可以被完美逆运算消除的操作，都不会改变系统的实际行为，因此也不会提供任何防御效果。防御的随机性必须来自**不可逆的信息注入**（如真正改变 ODE 物理轨迹的噪声），而不是可逆的坐标系变换。

2. **EOT 的收敛性由梯度一致性 $\rho$ 决定，而非参数空间的自由度**：正交群有 $10^6$+ 的自由度，但如果不同 $R_k$ 对最终输出没有影响，$\rho = 1$，EOT 一次就够了。自由度高不等于随机性强，随机性强不等于防御有效，防御有效的前提是随机性真正渗透进了输出结果。

3. **"在变换空间里看起来很复杂"不等于"真正改变了物理行为"**：需要养成习惯——对任何防御方案，都要做"等价简化检验"：把所有可逆操作消掉之后，系统还剩下什么？如果和基线完全一样，方案就是无效的。

4. **理论推导必须经得起代数展开的检验**：在高维几何直觉上看起来很复杂的方案，用链式法则逐步展开后可能极其简单。在投入大量实验资源之前，先做完整的代数展开验证是必要的。

---

## 五、对下一步的思考

要是还做针对白盒攻击的防御，我目前想法是继续看看能不能利用flow的路径可塑性来达到强随机性。但是这个方向并不简单，动机也是完全来自最新的文章，有点盲目追SOTA的嫌疑，也许寻找一些未被前人发现的小点更有可行性

若是不做白盒攻击，我目前想法是往迁移攻击上靠，但是这样就有点浪费之前一直在白盒攻击上耗费的成本，我目前对迁移攻击也知之甚少，只了解大概

---

## 六、向老师请教的问题

1. 就如上文第五大点所说，在大方向上，我应该把重心放在哪里呢
2. 在那个idea破产后，我有点陷入迷茫。虽然看起来是一个比较简单的尝试，但是也思考了有一阵子。本来验证完可行性我就打算写一个demo了，但是被证伪之后我一下子不知道该干什么了。**我不知道是我论文看的还不够还是什么问题，是看的少了还是做的少了，还是和老师交流过少了**。感觉看的论文也不少了（文中有些还未提及），复现也复现了两个，其中一个还是自己重构的，交流也有一直在向老师汇报。**对接下来努力的方式，我有点迷茫**
